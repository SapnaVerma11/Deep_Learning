{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "VGG16 on Skin Cancer Dataset.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "r6dsLNxdFytS"
      },
      "source": [
        "# importing the libraries\n",
        "import pandas as pd \n",
        "import numpy as np \n",
        "import tensorflow as tf \n",
        "from tensorflow.keras.layers import Dense,Flatten,Lambda,Input\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.applications.vgg16 import VGG16\n",
        "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator,load_img\n",
        "from glob import glob"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ixalbcatIN-a"
      },
      "source": [
        "#re-size all the images to this \n",
        "Image_Size = [224,224]\n",
        "\n",
        "train_path = \"/content/drive/MyDrive/Skin_Cancer_train_data\"\n",
        "valid_path = \"/content/drive/MyDrive/Skin_Cancer_test_data\""
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SVRnLleQJ3q6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c798ad8a-3ab5-47e5-f27a-e770b7e5e34b"
      },
      "source": [
        "# import the Vgg16 library as shown below and add preprocessing layerto the front of VGG\n",
        "# here we will be using imagenet weights. if it is not given weights will not be using weights for image classification using vgg16 in imagenet competiton \n",
        "# include_top = False means we are removing vgg16 layers from flatten till output layer so that we add our own layers \n",
        "# by giving input shape we have added our own input layer\n",
        "\n",
        "vgg16 = VGG16(input_shape=Image_Size + [3],weights='imagenet',include_top=False) \n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58892288/58889256 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tKMPEoQtOvd7",
        "outputId": "7a8108d4-97d0-4b53-cf28-fb9a256694f3"
      },
      "source": [
        "vgg16.summary()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"vgg16\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
            "=================================================================\n",
            "Total params: 14,714,688\n",
            "Trainable params: 14,714,688\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LercWOApO4Pb"
      },
      "source": [
        "#don't train existing weights \n",
        "for layer in vgg16.layers:\n",
        "  layer.trainable = False\n",
        "  "
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DuhK3dnrQSrp"
      },
      "source": [
        "#useful for getting number of output classes\n",
        "folders = glob(\"/content/drive/MyDrive/Skin_Cancer_train_data/*\")"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gWWbacT_Q6sk",
        "outputId": "b1171c64-542f-42d1-f73b-f698c8a67bda"
      },
      "source": [
        "folders"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/drive/MyDrive/Skin_Cancer_train_data/malignant',\n",
              " '/content/drive/MyDrive/Skin_Cancer_train_data/benign']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EcTS3XtSQ73U"
      },
      "source": [
        "# our own layer \n",
        "x = Flatten()(vgg16.output)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tnpT859aR4Hl"
      },
      "source": [
        "prediction = Dense(len(folders),activation='softmax')(x)\n",
        "\n",
        "# create a model object \n",
        "model = Model(inputs = vgg16.input,outputs = prediction)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JJ1CJxnDSh5o",
        "outputId": "d1c7a001-6eb5-4d5c-92c9-cbdc8b41476c"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 25088)             0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 2)                 50178     \n",
            "=================================================================\n",
            "Total params: 14,764,866\n",
            "Trainable params: 50,178\n",
            "Non-trainable params: 14,714,688\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L6H607sUTdd6"
      },
      "source": [
        "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oW20WrUHUYG7"
      },
      "source": [
        "train_datagen = ImageDataGenerator(rescale=1./255,horizontal_flip=True,shear_range=0.2,zoom_range=0.2)\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZNchWv6PUpMO",
        "outputId": "0768b702-b110-48ab-f3e1-8ce669a78744"
      },
      "source": [
        "training_set = train_datagen.flow_from_directory(\"/content/drive/MyDrive/Skin_Cancer_train_data\",\n",
        "                                                 target_size =(224,224),\n",
        "                                                 batch_size =32,\n",
        "                                                 class_mode='categorical')"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 2637 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nSg1Kxq_VUSw",
        "outputId": "01dd33c7-33ad-4970-d9ee-f7fe889bc8d1"
      },
      "source": [
        "testing_set = test_datagen.flow_from_directory(\"/content/drive/MyDrive/Skin_Cancer_test_data\",\n",
        "                                                 target_size =(224,224),\n",
        "                                                 batch_size =32,\n",
        "                                                 class_mode='categorical')"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 660 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XFDKU4U3Vxpb",
        "outputId": "0ed6294c-2724-4329-8a14-5c9c21bb5ebe"
      },
      "source": [
        "model.fit_generator(training_set,validation_data=testing_set,epochs=2)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "83/83 [==============================] - 1750s 21s/step - loss: 0.7486 - accuracy: 0.6759 - val_loss: 0.3680 - val_accuracy: 0.8348\n",
            "Epoch 2/2\n",
            "83/83 [==============================] - 48s 576ms/step - loss: 0.3537 - accuracy: 0.8388 - val_loss: 0.3363 - val_accuracy: 0.8530\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fe0a864bbd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VJun0qJHXjgc"
      },
      "source": [
        "import numpy as np \n",
        "from tensorflow.keras.preprocessing import image\n",
        "test_image = image.load_img(\"/content/drive/MyDrive/Skin_Cancer_test_data/benign/1003.jpg\",target_size = (224,224))\n",
        "test_image = image.img_to_array(test_image)\n",
        "test_image=test_image/255\n",
        "test_image = np.expand_dims(test_image, axis = 0)\n",
        "result = model.predict(test_image)\n"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x6IYEjqtc4xY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d0419d3-f138-41b8-9cf6-f084dc587cc8"
      },
      "source": [
        "result"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.918031, 0.081969]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JvFzWQ0CbFRK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "341c4d49-1fe9-4743-e35f-f319be948a72"
      },
      "source": [
        "a = np.argmax(model.predict(test_image),axis=1)\n",
        "a"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "44wal2SRcYHo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d5cd3ff-b4a5-4e8c-9096-bc53998f7e07"
      },
      "source": [
        "if a==0:\n",
        "  print(\"The image classified is Benign\")\n",
        "else:\n",
        "  print(\"The image classified is Malignant\")  "
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The image classified is Benign\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}